name: Workflow to trigger manually

on:
  workflow_dispatch:
    inputs:
      valuesToFilterBy:
        description: 'Specify values to filter records by (use comma without spaces if there are more than one)'
        required: true
        default: 'United Kingdom,Netherlands'

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.7
      uses: actions/setup-python@v3
      with:
        python-version: "3.7"
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Unit tests
      run: python -m pytest
    
    - name: Run app and log events
      run: |
        cp src/{app.py,app_functions.py} .
        python app.py --df1_path dataset_one.csv --df2_path dataset_two.csv --values_to_filter "${{ github.event.inputs.valuesToFilterBy }}"

    - name: Commit generated files to the repository
      run: |
        rm -f app.py -f app_functions.py
        git config --local user.email "action@github.com"
        git config --local user.name "github-actions"
        git add .
        git commit -m "Add generated files"
        git branch -M main
        git remote add origin-pyspark-app https://github.com/CyberIgor/Simple-PySpark-app-Test
        git push origin-pyspark-app main

    - name: Package app into a source distribution file
      run: python setup.py sdist

    - name: Upload artifact
      uses: actions/upload-artifact@v2
      with:
        name: KaommatiPara-data-analysis-pack
        path: ./dist/
